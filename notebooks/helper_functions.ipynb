{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "78e3348f-25df-42ec-ba10-820f1acc8b8a",
   "metadata": {},
   "source": [
    "# Growth Model Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c8b30aaa-7f0a-43f3-bf26-7ae2c0445c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pmdarima.arima import auto_arima\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "import mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5c438317-c29f-49ef-a22e-99269dc376a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_future_rows(df, num_rows):\n",
    "    # Convert 'date' column to datetime type\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "\n",
    "    # Get the maximum tenure for each customer id, managed service, and geo combination\n",
    "    max_tenure = df.groupby(['account_name'])['tenure'].max()\n",
    "\n",
    "    new_rows = []\n",
    "    for idx, max_tenure in max_tenure.items():\n",
    "        customer_id = idx\n",
    "        # Get the last row for the account id\n",
    "        last_row = df[df['account_name'] == customer_id].iloc[-1]\n",
    "\n",
    "        for i in range(num_rows):\n",
    "            new_row = last_row.copy()\n",
    "            new_row['date'] = last_row['date'] + pd.DateOffset(months=i+1)\n",
    "            new_row['tenure'] = max_tenure + i + 1\n",
    "            new_row['value'] = np.nan  # Set curr_mnth_rev to NaN for new rows\n",
    "            new_rows.append(new_row)\n",
    "\n",
    "    # Create a DataFrame from the new rows\n",
    "    new_rows_df = pd.DataFrame(new_rows)\n",
    "\n",
    "    # Concatenate the new rows with the original dataframe\n",
    "    df = pd.concat([df, new_rows_df], ignore_index=True)\n",
    "\n",
    "    # Sort the dataframe by customer_id, managed_service, geo, and date\n",
    "    df.sort_values(['account_name', 'date'], inplace=True)\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2db8b633-a0b0-44e6-96b1-80ef746bfc4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def symmetric_mean_absolute_percentage_error(actual, forecast):\n",
    "    actual = np.array(actual)\n",
    "    forecast = np.array(forecast)\n",
    "    result = np.mean(np.abs(actual - forecast) / ((np.abs(actual) + np.abs(forecast)) / 2))\n",
    "    return 0 if np.isnan(result) else result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9020eaa4-21eb-4094-80f7-0a2bee2ab799",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forecast(g, train_start_date, train_end_date, test_start_date, test_end_date, forecast_start_date, forecast_end_date, regressor_cols):\n",
    "    # filter data based on dates\n",
    "    train_data = g.loc[(g.index.get_level_values('date') >= train_start_date) & (g.index.get_level_values('date') <= train_end_date)]\n",
    "    test_data = g.loc[(g.index.get_level_values('date') >= test_start_date) & (g.index.get_level_values('date') <= forecast_end_date)]\n",
    "    #forecast_data = g.loc[(g.index.get_level_values('date') >= forecast_start_date) & (g.index.get_level_values('date') <= forecast_end_date)]\n",
    "\n",
    "    # auto arima\n",
    "    model = auto_arima(train_data['value'], exogenous=train_data[regressor_cols],\n",
    "                       seasonal=False, trace=False,\n",
    "                       suppress_warnings=True, error_action=\"ignore\", stepwise=True,\n",
    "                       start_p=0, start_q=0, max_order=None, method='nm',\n",
    "                       maxiter=100, n_jobs=-1) #Akaike Information Criterion.\n",
    "\n",
    "    # fit model on the training dataset only\n",
    "    model.fit(train_data['value'], exogenous=train_data[regressor_cols]) \n",
    "\n",
    "    # predict values for test and forecasting dataset\n",
    "    valid = model.predict(n_periods=len(test_data), exogenous=test_data[regressor_cols])\n",
    "    #forecast = model.predict(n_periods=len(forecast_data), exogenous=forecast_data[regressor_cols])\n",
    "    \n",
    "    valid = list(valid)\n",
    "    #forecast= list(forecast)\n",
    "    #print(\"Valid:\", valid)\n",
    "\n",
    "    # calculate monthly MAPE and SMAPE\n",
    "    monthly_mape = pd.DataFrame({'MAPE': np.zeros(len(valid))}, index=test_data.index)\n",
    "    monthly_smape = pd.DataFrame({'SMAPE': np.zeros(len(valid))}, index=test_data.index)\n",
    "\n",
    "    for i in range(3):\n",
    "        #print(\"test_data\",test_data.iloc[0,1])\n",
    "        #print(valid[i:i+1])\n",
    "        monthly_mape.iloc[i] = mean_absolute_percentage_error(test_data.iloc[i:i+1, 1], valid[i:i+1])\n",
    "        #print(monthly_mape.iloc[i])\n",
    "        monthly_smape.iloc[i] = symmetric_mean_absolute_percentage_error(test_data.iloc[i:i+1, 1], valid[i:i+1])\n",
    "        \n",
    "    # create a new dataframe with the forecasted values, MAPE and SMAPE\n",
    "    result = pd.DataFrame({'validated_value': valid,\n",
    "                           'MAPE_monthly': monthly_mape['MAPE'],\n",
    "                           'SMAPE_monthly': monthly_smape['SMAPE']},\n",
    "                          index=test_data.index)\n",
    "    \n",
    "    # create a new dataframe with the forecasted values, MAPE and SMAPE\n",
    "    #forecast = pd.DataFrame({'forecasted_curr_mnth_rev': forecast},\n",
    "    #                         index=forecast_data.index)\n",
    "\n",
    "    # merge the result with the original group\n",
    "    result = pd.concat([g, result], axis=1)\n",
    "    #result = pd.concat([forecast, result], axis=1)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d1b9ea92-88f7-4721-8ebd-59233ff172ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_mlflow(cs_type, experiment, mlflow_run_name, median_mape_df):\n",
    "# Create a new run in mlflow\n",
    "    with mlflow.start_run(experiment_id = experiment.experiment_id, run_name=mlflow_run_name):\n",
    "        parameters ={\n",
    "            'cloud_service_type': cs_type,\n",
    "            'model': 'ARIMA Regressor'\n",
    "        }\n",
    "        \n",
    "        mlflow.log_params(parameters)\n",
    "            \n",
    "        metrics ={\n",
    "            'MAPE_month1': median_mape_df[0],\n",
    "            'MAPE_month2': median_mape_df[1], \n",
    "            'MAPE_month3': median_mape_df[2]\n",
    "        }\n",
    "        \n",
    "        mlflow.log_metrics(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d0703e6a-9142-41a3-a1e5-61b4e74946dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_time_series(df ,account_name):\n",
    "    # Load the dataset into a pandas DataFrame\n",
    "\n",
    "    # Filter the data based on customer_id, service, and location\n",
    "    filtered_data = df[(df['account_name'] == account_name)]\n",
    "    \n",
    "    valid_data = filtered_data[(filtered_data['month'] >= '2015-01-01') & ((filtered_data['month'] <= '2015-03-01'))]\n",
    "    pred_data = filtered_data[(filtered_data['month'] >= '2015-04-01') & ((filtered_data['month'] <= '2015-09-01'))]\n",
    "\n",
    "    # Plotting revenue, validation, and forecasted revenue\n",
    "    plt.figure(figsize=(16, 8))\n",
    "    plt.plot(filtered_data['month'], filtered_data['actual_mnth_value$'], marker='o', label='actual_mnth_value$')\n",
    "    plt.plot(valid_data['month'], valid_data['predicted_mnth_value$'], marker='o', label='valid_mnth_value$')\n",
    "    plt.plot(pred_data['month'], pred_data['predicted_mnth_value$'], marker='o', label='predicted_mnth_value$')\n",
    "\n",
    "    plt.xlabel('Date', fontsize=12)\n",
    "    plt.ylabel('Revenue', fontsize=12)\n",
    "    plt.title(f'Time Series Analysis for Customer: {account_name}')\n",
    "    plt.legend()\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f6605db1-86e6-4c28-a4d7-2f3664d8d3fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate the slope and median predicted monthly revenue for each customer prediction curve\n",
    "def find_slope_and_median(x):\n",
    "    from sklearn import linear_model\n",
    "    reg = linear_model.LinearRegression()\n",
    "    reg.fit(x['date_ordinal'].values.reshape(-1, 1), x['predicted_mnth_value$'].values)\n",
    "    slopes = reg.coef_\n",
    "    median_predicted_value = x['predicted_mnth_value$'].median()\n",
    "    return pd.Series([slopes[0], median_predicted_value], index=['slope', 'median_predicted_value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "74859ae9-8d88-4182-bd0f-279aba5a8299",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cluster_and_label_based_on_centroids(df, n):\n",
    "    from sklearn.cluster import KMeans\n",
    "    X = df[['slope_scaled']].values.reshape(-1, 1)\n",
    "    kmeans_model = KMeans(n_clusters=n, init='k-means++', random_state=0)\n",
    "    kmeans_model.fit(X)\n",
    "    centroids = kmeans_model.cluster_centers_\n",
    "    centroid_indices = np.argsort(centroids[:, 0])\n",
    "    cluster_labels = np.zeros_like(kmeans_model.labels_)\n",
    "    label_mapping = {0: \"low\", 1: \"medium\", 2: \"high\"}\n",
    "    for i, centroid_index in enumerate(centroid_indices):\n",
    "        cluster_labels[kmeans_model.labels_ == centroid_index] = i\n",
    "    cluster_labels = np.vectorize(label_mapping.get)(cluster_labels)\n",
    "    df['cluster_label'] = cluster_labels\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c055b15d-7b3c-4543-b176-0e287fcdbd55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df of accounts wrt labels\n",
    "def list_account_with_labels(df,label):\n",
    "    return df[df['cluster_label'] == label].sort_values('median_predicted_value', ascending=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.14",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
